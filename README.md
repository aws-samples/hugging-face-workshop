## Hugging Face on Amazon SageMaker and AWS Workshop

You’ve just been hired by the Chicago Tribune to start a new poetry column. Congrats! The catch? You need to write a new poem every day. And it can’t just be any old string of syllables, you need it to be fresh, authentic, to resonate with the times and carry a sense of rhyme. You need it to delight your readers, to drive up the Tribune’s daily readership numbers and grow their social media presence. How are you going to accomplish this? With the help of Hugging Face and NLP models on SageMaker of course! 

In this 90-minute hands-on workshop you will use prebuilt notebooks to fine-tune text generation models in the style of your favorite poets, on Amazon SageMaker. You will customize your notebooks to generate new lines of poetry that seem promising, and publish these onto an S3 bucket. You will use *SageMaker training to fine-tune your models* on larger sets of data, speeding up your train time with the SageMaker Training Compiler

Additionally, we'll provide links to explain *model performance with SageMaker Clarify*, and *tune your hyper-parameters with Automatic Model Tuning.* You’ll see how to optimize your models for performance with the SageMaker *Inference Recommender*, ultimately compiling your model for enhanced inference times with SageMaker Neo. 

You will build a *multi-model endpoint on SageMaker to deploy models* with different styles of text generation, fine-tuned for different authors, and combine all of them to write different styles of poetry. Lastly, you’ll wrap your work into a *SageMaker Pipelines workflow* to push new changes to your models as new topics become more relevant. 

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This project is licensed under the Apache-2.0 License.

